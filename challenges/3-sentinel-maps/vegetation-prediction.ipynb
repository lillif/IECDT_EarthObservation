{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vegetation Prediction using Sentinel-2\n",
    "\n",
    "In this computing lab, you will create a simple machine learning model to predict vegetation percentage from Sentinel-2 imagery. The Copernicus Sentinel-2 mission is organized as a constellation of identical satellites in the same orbit: Sentinel-2A launched in 2015, Sentinel-2B launched in 2017, and Sentinel-2C launched in September of this year. Each satellite carries a multispectral imager with 13 spectral bands to measure our land and vegetation.\n",
    "\n",
    "<img src=images/sentinel-2.jpg alt=\"Sentinel 2\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Learning Objectives\n",
    "The goals of this computing lab are to:\n",
    "\n",
    "1. Familiarize yourself with the structure of Sentinel-2 data\n",
    "2. Visualize sample Sentinel-2 imagery and corresponding vegetation labels\n",
    "3. Create a supervised machine learning pipeline using Pytorch Lightning and develop e.g.\n",
    "    - dataloaders\n",
    "    - data augmentations & transformations\n",
    "    - (one or more) machine learning models\n",
    "    - validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2. Data Exploration\n",
    "\n",
    "Let's start by exploring the satellite data you will work with. You can download Sentinel-2 data directly from ```Copernicus``` (https://browser.dataspace.copernicus.eu/) or via platforms like ```Google Earth Engine``` (https://earthengine.google.com/). After creating an account, these platforms allow you to visualize and query EO data via their web interfaces, and provide support to download larger amounts of data via the command line or python scripts.\n",
    "After downloading, it is usually a non-trivial amount of work to prepare EO data for machine learning purposes. Depending on your application, you might want to mask clouds, calculate weekly/monthly/seasonal summaries, adjust the range of pixel values etc. In addition, since EO images are often very large, you need to decide on a patching strategy to create machine learning ready data tiles that are large enough to contain relevant information, but small enough to fit into memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1. Area of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, we have already downloaded and prepared ML-ready data for you! For this lab, we will focus on data from 2020 in Oxfordshire. To download the data, we create a wkt shape file of the county boundaries of Oxfordshire, and used ```geetiles``` (https://github.com/rramosp/geetiles) to download spatially aligned data tiles. We highly recommend looking into this tool, if you plan to use ```Google Earth Engine``` for your research. If you run the cell below, you can visualize what the spatial coverage of the tiles looks like. Each tile covers 1280 m x 1280 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "# Step 1: Load the GeoJSON file\n",
    "geojson_file = \"oxfordshire_partitions_aschips_2c696f57ca1c0.geojson\"\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "# Step 2: Plot the GeoDataFrame with no fill color and thin outlines\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Step 3: Add a basemap\n",
    "ctx.add_basemap(ax, crs=gdf.crs.to_string())\n",
    "\n",
    "# Step 4: Customize the plot\n",
    "ax.set_title(\"Overview of available data tiles in Oxfordshire\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How many data tiles are there in total?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Data Variables & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have looked at our area of interest, let's investigate the data we will use, saved in ```/work/scratch-nopw2/iecdt_ai4eo/data```. In this folder, you find Sentinel-2 imagery (sentinel2-2020) and vegetation labels (vegetation-2020). The vegetation labels are provided by NASA, and were derived from MODIS measurements (see https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD44B).\n",
    "\n",
    "In the data repository, each folder contains the same number of files, labeled with a unique identifier for each data tile shown above. In the cells below, pick a few identifiers and investigate what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define data paths\n",
    "base_path = 'PATH/TO/DATA'\n",
    "s2_path = 'PATH/TO/S2-DATA'\n",
    "veg_path = 'PATH/TO/VEG-DATA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What can you learn about the data and variables stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Plot a few example tiles, and investigate what the data looks like. Can you create a proper RGB image of the Sentinel-2 data? What do you learn about the resolution of the datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the vegetation labels contain information on the percent tree cover for the years 2016 - 2020 (although we will only use data from 2020 today).\n",
    "Our Sentinel-2 data contains seasonal summaries (Spring: Mar - May, Summer: Jun - Aug, Fall: Sep - Nov, Winter: Dec - Feb) for the high resolution (10-20 m) channels:\n",
    "\n",
    "<img src=images/sentinel-2-bands.png alt=\"Sentinel 2 Bands\" width=400>\n",
    "\n",
    "**Question**: Which bands do you estimate are the most useful for vegetation prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pipeline Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have investigated our data, we will develop our training pipeline, consisting of a dataloader, model, trainer, and evaluation metrics. Note, since the resolution of the vegetation labels is much coarser than the resolution of the Sentinel-2 imaergy, we will focus on predicting the **mean vegetation percentage** of each tile, i.e. a regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Datasets & Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with creating our dataloader. For this, we will first create a dataset that loads one image at a time, and feed this to a Pytorch dataloader that will create batches for training. We have started developing the code for you below, but a few lines are missing that you should fill in. Make sure that you test your dataloader for different experimental configurations.\n",
    "\n",
    "To make dataloading easier, we prepared a csv file for you (```oxfordshire_partitions_aschips_2c696f57ca1c0_splits.csv```), that contains information on which tiles should be used for training, validation, and testing. While there are different ways to split your data, we have opted to split our data by geographics bands (also using ```geetiles```). If you run the cell below, you can visualize what the data splits look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Load the GeoJSON file\n",
    "geojson_file = \"oxfordshire_partitions_aschips_2c696f57ca1c0.geojson\"\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot each split separately\n",
    "gdf[gdf['split'] == 'train'].plot(ax=ax, facecolor='red', edgecolor='black', linewidth=0.5)\n",
    "gdf[gdf['split'] == 'val'].plot(ax=ax, facecolor='blue', edgecolor='black', linewidth=0.5)\n",
    "gdf[gdf['split'] == 'test'].plot(ax=ax, facecolor='green', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Add a basemap\n",
    "ctx.add_basemap(ax, crs=gdf.crs.to_string())\n",
    "\n",
    "# Add a legend\n",
    "# Create custom legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', edgecolor='black', label='Train'),\n",
    "    Patch(facecolor='blue', edgecolor='black', label='Validation'),\n",
    "    Patch(facecolor='green', edgecolor='black', label='Test')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Tiles & splits\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What are some of the considerations when deciding on data splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from typing import List\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_dir: str,\n",
    "        files: List[str],\n",
    "        seasons: List[str],\n",
    "        bands: List[str],\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.files = files\n",
    "        self.seasons = seasons\n",
    "        self.bands = bands\n",
    "\n",
    "        self.s2_path = os.path.join(data_dir, 'sentinel2-2020')\n",
    "        self.veg_path = os.path.join(data_dir, 'vegetation-2020')\n",
    "\n",
    "        self.s2_bands = [f\"{season}_{band}\" for season in seasons for band in bands]\n",
    "        self.veg_bands = ['Percent_Tree_Cover_2020']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Compile file path\n",
    "        s2_path = os.path.join(self.s2_path, f'{self.files[idx]}.tif')\n",
    "        veg_path = os.path.join(self.veg_path, f'{self.files[idx]}.tif')\n",
    "\n",
    "        # TODO: Add code for opening and preprocessing the data\n",
    "        # NOTE: To start, we want to predict the mean vegetation percent per tile\n",
    "\n",
    "        # TODO: Return a tuple of (img, veg_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning.pytorch import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Callable\n",
    "\n",
    "class Dataloader(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        split_file: str,\n",
    "        seasons: List[str],\n",
    "        bands: List[str],\n",
    "        batch_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.split_file = pd.read_csv(split_file)\n",
    "        self.seasons = seasons\n",
    "        self.bands = bands\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Get list of files for each split\n",
    "        self.train_files = self.split_file[self.split_file['split'] == 'train']['identifier'].tolist()\n",
    "        self.val_files = self.split_file[self.split_file['split'] == 'val']['identifier'].tolist()\n",
    "        self.test_files = self.split_file[self.split_file['split'] == 'test']['identifier'].tolist()\n",
    "\n",
    "        self.train_dataset = Dataset(\n",
    "            data_dir=self.data_dir,\n",
    "            files=self.train_files,\n",
    "            seasons=self.seasons,\n",
    "            bands=self.bands\n",
    "        )\n",
    "        self.val_dataset = Dataset(\n",
    "            data_dir=self.data_dir,\n",
    "            files=self.val_files,\n",
    "            seasons=self.seasons,\n",
    "            bands=self.bands\n",
    "        )\n",
    "        self.test_dataset = Dataset(\n",
    "            data_dir=self.data_dir,\n",
    "            files=self.test_files,\n",
    "            seasons=self.seasons,\n",
    "            bands=self.bands\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False,\n",
    "            )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a working dataloader, we can now turn to developing our machine learning model. For now, we will experiment with a simple CNN regression model. If you finish early, you are very welcome to experiment with adapting this model or implementing other approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from lightning.pytorch import LightningModule\n",
    "\n",
    "class CNN_Regression(LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_shape: tuple,\n",
    "        learning_rate: float,\n",
    "        output_dim: int = 1, # Regression output is just one value\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.input_channels = input_shape[0]\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # define & log hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # model architecture\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=self.input_channels,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=2)\n",
    "\n",
    "        # activation function\n",
    "        self.activation_fn = F.relu\n",
    "        self.output_activation_fn = F.elu\n",
    "\n",
    "        # pooling layer\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # compute the flattened size of the output tensor\n",
    "        hidden_dim = self._get_output_shape(self.input_shape)\n",
    "\n",
    "        # linear layers for regression head\n",
    "        self.fc1 = nn.Linear(hidden_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.output_layer = nn.Linear(128, output_dim)\n",
    "\n",
    "        # criterion\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def _get_output_shape(self, shape):\n",
    "        \"\"\"returns the size of the output tensor after the conv layers\"\"\"\n",
    "        batch_size = 1\n",
    "        # initialize random input tensor\n",
    "        input = torch.rand(batch_size, *shape, requires_grad=True)\n",
    "        # forward pass through the conv layers\n",
    "        output_feature = self.feature_extractor(input)\n",
    "        hidden_dim = output_feature.data.view(batch_size, -1).size(1)\n",
    "        return hidden_dim\n",
    "    \n",
    "    def _get_number_parameters(self):\n",
    "        \"\"\"returns the number of trainable parameters\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    # backbone to extract features from input imagery\n",
    "    def feature_extractor(self, x):\n",
    "        \"\"\"extract features from the conv blocks\"\"\"\n",
    "        x = self.activation_fn(self.conv1(x))\n",
    "        x = self.pool1(self.activation_fn(self.conv2(x)))\n",
    "        x = self.activation_fn(self.conv3(x))\n",
    "        x = self.pool2(self.activation_fn(self.conv4(x)))\n",
    "        return x\n",
    "\n",
    "    # forward function to extract features and predict output\n",
    "    def forward(self, x):\n",
    "        \"\"\"produce final model output\"\"\"\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1) # reshapes the tensor to (batch_size, hidden_dim)\n",
    "\n",
    "        # TODO: Add forward pass for regression head\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def compute_loss(self, batch):\n",
    "        input, labels = batch\n",
    "        # TODO: Add forward pass and computation of loss\n",
    "        predictions = ...\n",
    "        loss = ...\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch)\n",
    "        # log training loss\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch)\n",
    "        # log validation loss\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch)\n",
    "        # log test loss\n",
    "        self.log(\n",
    "            \"test_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the training. For this, we can use the Pytorch Lightning Trainer, which wraps all code for the training loop conveniently for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "seed_everything(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why do we need to define a random seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataloader\n",
    "dl = Dataloader(\n",
    "    data_dir=base_path,\n",
    "    split_file=\"oxfordshire_partitions_aschips_2c696f57ca1c0_splits.csv\",\n",
    "    batch_size=...,\n",
    "    seasons=...,\n",
    "    bands=...,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model \n",
    "model = CNN_Regression(\n",
    "    input_shape=...,\n",
    "    output_dim=...,\n",
    "    learning_rate=...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(\"logs\", name=\"vegetation-prediction\")\n",
    "\n",
    "num_epochs = ...\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=10)],\n",
    "    logger=logger,\n",
    "    devices=1,\n",
    "    accelerator='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "trainer.fit(model, dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4. Metrics & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the training and validation losses, for instance through tensorboard. If you run the next line, an interactive window should appear, that allows you to plot the loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have reached the end of the notebook, there are a few areas you can explore:\n",
    "\n",
    "- How well does the model perform? Can you improve the prediction results? For instance, you might experiment with the learning rate, model architecture, loss functions, data augmentations etc.\n",
    "\n",
    "- How does the availability of input channels impact the prediction results? Are all seasons required to predict yearly vegetation maps? How does the model perform if you give it more or fewer spectral channels? Does this match what you would expect?\n",
    "\n",
    "- Are there any other other model architectures (or baselines) to implement?\n",
    "\n",
    "- What other metrics could you log during training?\n",
    "\n",
    "- Can you create prediction maps of your model (and the ground truth)? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iecdt-earth-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
