{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sun Prediction using the AOPP weather station and MODIS\n",
    "\n",
    "\n",
    "In this lab, you will create a simple machine learning model to predict how sunny it will be in Oxford in the afternoon using [AOPP weather station measurements](https://weatherstationdata.physics.ox.ac.uk) and [MODIS-Terra](https://modis.gsfc.nasa.gov/about/) images. Since 2012, the AOPP weather station measures the average wind, temperature, pressure, and humidity over the last ten seconds, every ten seconds. Terra is a sun-synchronous satellite that observes the Earth during the morning (local time), and acquires global coverage every 1-2 days. The MODIS instrument takes images in [36 spectral bands](https://modis.gsfc.nasa.gov/about/specifications.php)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Objectives\n",
    "The goals of this lab are to:\n",
    "\n",
    "1. Familiarize yourself with weather station observations and MODIS satellite data\n",
    "2. Visualize time series of weather station data and sample MODIS images\n",
    "3. Train a simple baseline model to get to know the prediction task.\n",
    "4. Create a supervised machine learning pipeline using Pytorch Lightning and develop\n",
    "    - dataloaders\n",
    "    - data augmentations & transformations\n",
    "    - (one or more) machine learning models\n",
    "    - validation metrics\n",
    "5. Explore interpretability, predictability, & model improvements\n",
    "\n",
    "Throughout the lab, you'll find skeleton implementations containing `...` in places that need filling in to carry out the experiments.\n",
    "\n",
    "#### 1.1. ML Task\n",
    "We are trying to predict **how much sun we should expect in the afternoon (between 13:00 and 20:59)**, based on how sunny the previous 3 afternoons have been (plus other weather station measurements from the past 3 days), as well as a satellite image from the morning (around 11am) of the same day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration\n",
    "First, let's explore the two datasets that you will work with. We are using weather station measurements and MODIS observations from 2016 to 2021.\n",
    "\n",
    "#### 2.1. Weather Station\n",
    "\n",
    "The observations have been pre-processed for this lab, to create a dataset with one entry for each day. Each row in the processed dataset contains:\n",
    "\n",
    "Name | Description | Unit\n",
    "--- | --- | --- |\n",
    "date | | yyyy-mm-dd\n",
    "total_sun_per_day | the total amount of sunshine | hours of sunshine\n",
    "mean_wind_per_day | the average wind speed | metres per second\n",
    "mean_wind_direction_per_day | the average direction of the wind | degrees\n",
    "mean_temperature_per_day | the average temperature | degrees Celsius\n",
    "total_rain_per_day | the total amount of rain | millimetres\n",
    "mean_pressure_per_day | the average pressure | hectopascal\n",
    "total_sun_1to8pm | the amount of sunshine between 13:00 and 20:59pm | hours of sunshine (0 to 8)\n",
    "mean_wind_direction_9to10am | the average direction of the wind between 9 and 10am | degrees \n",
    "mean_wind_9to10am | the average wind speed between 9 and 10am | metres per second\n",
    "mean_humidity_9to10am | the average relative humidty between 9 and 10am | percent\n",
    "mean_pressure_9to10am | the average pressure between 9 and 10am | hectopascal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "DATA_PATH = pathlib.Path('/gws/nopw/j04/iecdt/ai4eo/data/1-sunny-oxford/')\n",
    "if DATA_PATH.exists():\n",
    "    print(\"Storing data on JASMIN\")\n",
    "else:\n",
    "    DATA_PATH = pathlib.Path(\"../../data/1-sunny-oxford\")\n",
    "    print(\"Storing data locally\")\n",
    "    if not DATA_PATH.exists():\n",
    "        DATA_PATH.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "station_paths = glob.glob('../../data/1-sunny-oxford/weatherstation/*')\n",
    "station_dfs = [pd.read_csv(station_path) for station_path in station_paths]\n",
    "\n",
    "weather_station = pd.concat(station_dfs, ignore_index=True).sort_values(by='date').reset_index(drop=True)\n",
    "weather_station['date'] = pd.to_datetime(weather_station['date'])\n",
    "\n",
    "weather_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# plot daily sun hours\n",
    "plt.plot(weather_station['date'], weather_station['total_sun_1to8pm'], '-x')\n",
    "plt.title('Sun hours after 1 pm each day in 2021')\n",
    "plt.ylabel('Sun after 1 pm')\n",
    "\n",
    "plt.xlim(weather_station['date'].min(), weather_station['date'].max())\n",
    "plt.ylim(-5, 10)\n",
    "\n",
    "# set xticks and xlabels to every 6 months\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in measurements are denoted by `-999` - this can create very large negative numbers if a sensor takes invalid measurements for a period of time when summed over each day. We also know that there is a strict upper bound for the amount of sunshine hours that can be measured between 1pm and 8:59pm. We therefore remove invalid measurements for our experiments.\n",
    "\n",
    "**Question:** Based on our knowledge about the data, what would be sensible lower and upper bounds on our measurements? Fill in the values below and look at the new timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "sun_data = weather_station['total_sun_1to8pm'].to_numpy()\n",
    "sun_data[(sun_data > ...) | (sun_data < ...)] = np.nan # TODO: replace ... with a lower and upper bound\n",
    "\n",
    "dates = weather_station['date'].to_numpy()\n",
    "\n",
    "# plot daily sun hours\n",
    "plt.plot(weather_station['date'], sun_data, '-x')\n",
    "plt.title('Sun hours after 1 pm each day in 2021')\n",
    "plt.ylabel('Sun after 1 pm')\n",
    "\n",
    "plt.xlim(dates[0], dates[-1])\n",
    "\n",
    "# set xticks and xlabels to every 6 months\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you notice about our dataset? Which aspects might affect machine learning models that are trained to predict sun throughout the year?\n",
    "\n",
    "One common way to study timeseries is to compute the Autocorrelation timescale. It refers to the amount of time over which the values in the dataset are correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "sun_data_nonan = sun_data[~np.isnan(sun_data)]\n",
    "\n",
    "# compute the autocorrelation function\n",
    "lags = 90  # Number of lags to compute\n",
    "acf_values = acf(sun_data_nonan, nlags=lags, fft=True)\n",
    "\n",
    "# estimate autocorrelation timescale\n",
    "autocorrelation_timescale = 1 + 2 * np.sum(acf_values[1:]) \n",
    "\n",
    "plt.stem(range(len(acf_values)), acf_values)\n",
    "plt.xlabel(\"Lag [days]\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.title(\"Autocorrelation of Afternoon Sun\")\n",
    "plt.text(40, 0.9, f\"Autocorrelation Timescale: {autocorrelation_timescale:.1f}\", color='darkblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation timescale measures how long the effect of a particular value persists in the time series before the series \"forgets\" it and becomes statistically independent. For an autocorrelation timescale of 17 days, this means the value of the dataset at a given time provides you with information to predict future values up to the next ~17 days.\n",
    "\n",
    "**Question:** How is this relevant to our prediction task? Thinking of the task at hand, can you think of any 'slow' weather / climate processes that explain such long memory in our timeseries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. MODIS Images\n",
    "You can download MODIS data directly from NASA's [EarthData](https://earthdata.nasa.gov) platform using the python package `earthaccess` (https://earthaccess.readthedocs.io/) as shown in the example below. After downloading, a variety of processing steps are required to get your satellite dataset machine learning-ready. For example, filtering out invalid or incomplete observations, remapping images onto a common grid, normalising each spectral channel, patching your dataset, etc.\n",
    "\n",
    "For the purpose of this lab, we already downloaded and prepared a small MODIS dataset. Run the cells below to explore the data format and visualise what the images look like.\n",
    "\n",
    "_______________\n",
    "Example earthaccess download script:\n",
    "\n",
    "```python\n",
    "import earthaccess\n",
    "auth_obj  = earthaccess.login('interactive')\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    # MOD = Terra, 02 = Level1B Radiances, 1KM  resolution (all 36 spectral bands)\n",
    "    short_name= 'MOD021KM', \n",
    "    # (lon min, lat min, lon max, lat max) - Oxford: 51.75° N, 1.26° W\n",
    "    bounding_box=(0.5, 51, 1.5, 52), \n",
    "    temporal=('2021-01-01', '2021-01-05'),\n",
    ")\n",
    "\n",
    "files = earthaccess.download(results, local_path='./')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import tempfile\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "MODIS_IMAGE_DIR = DATA_PATH/'modis'\n",
    "modis_image_files = sorted(list(MODIS_IMAGE_DIR.glob(\"*.nc\")))\n",
    "\n",
    "# Download and extract if missing\n",
    "if len(modis_image_files) == 0:\n",
    "    with tempfile.NamedTemporaryFile() as tmp:\n",
    "        print(\"Downloading https://zenodo.org/records/14203536/files/modis.zip\")\n",
    "        urllib.request.urlretrieve(\n",
    "            \"https://zenodo.org/records/14203536/files/modis.zip\", tmp.name\n",
    "        )\n",
    "        print(\"Extracting modis.zip\")\n",
    "        with zipfile.ZipFile(tmp, 'r') as zip_ref:\n",
    "            zip_ref.extractall(DATA_PATH)\n",
    "    \n",
    "    modis_image_files = sorted(list(MODIS_IMAGE_DIR.glob(\"*.nc\")))\n",
    "\n",
    "    assert len(modis_image_files), \"Download failed!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = xr.load_dataset(modis_image_files[0])\n",
    "sample_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIS is a multi-spectral satellite: it takes 36 images of each scene in 36 different wavelength channels. As you can see in the `Data variables`, MODIS channels 1 to 5 were processed. Their specifications are shown in the table below.\n",
    "\n",
    "![MODIS bands](./images/modis_bands.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotting such multi-spectral observations we can either plot a single channel (first example below) or create so-called RGB-composites (second example). RGB composites assign 3 channels to each of red, blue and green, and colour each pixel in the image based on the measurement values of the three channels in that pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "\n",
    "def plot_single_channel(ds, channel='1'):\n",
    "    data = ds[channel]\n",
    "    patch = data.isel(x=slice(60,188,2), y=slice(60,188,2))\n",
    "    \n",
    "    projection = ccrs.PlateCarree()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 7), subplot_kw={'projection': projection})\n",
    "    \n",
    "    data.isel(x=slice(None,None,2), y=slice(None,None,2)).plot(ax=ax, transform=projection, cmap='viridis', add_colorbar=False)\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([-3.5, 1.5, 49.5, 53.5], crs=projection)\n",
    "    \n",
    "    \n",
    "    # add gridlines for reference\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, alpha=0)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    \n",
    "    # add marker for Oxford\n",
    "    oxford_lon, oxford_lat = -1.2577, 51.7520\n",
    "    ax.plot(oxford_lon, oxford_lat, marker='x', color='white', markersize=6, label=\"Oxford\", transform=projection)\n",
    "    ax.text(oxford_lon-0.3, oxford_lat-0.3, 'Oxford', color='white', weight='bold', fontsize=10)\n",
    "    \n",
    "    # draw a rectangle around the area we are interested in\n",
    "    lons = [patch.x.min(), patch.x.max(), patch.x.max(), patch.x.min(), patch.x.min()]\n",
    "    lats = [patch.y.min(), patch.y.min(), patch.y.max(), patch.y.max(), patch.y.min()]\n",
    "    ax.plot(lons, lats, color='red', linewidth=1, transform=projection)\n",
    "    \n",
    "    plt.title(f\"MODIS band {data.name}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_single_channel(sample_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_rgb_false_color(ds):\n",
    "    def normalize(band, scaling_factor=1.3):\n",
    "        return (band - band.min()) / (band.max() - band.min()) * scaling_factor\n",
    "\n",
    "    patch = ds['1'].isel(x=slice(60,188,2), y=slice(60,188,2))\n",
    "    \n",
    "    rgb_bands = ['1', '4', '3']\n",
    "    \n",
    "    rgb = [ds[var] for var in rgb_bands]\n",
    "    rgb = [da.fillna(np.nanmean(da)) for da in rgb]\n",
    "    rgb = [normalize(da) for da in rgb]\n",
    "    rgb = xr.concat(rgb, dim='band').transpose('y', 'x', 'band')\n",
    "\n",
    "    projection = ccrs.PlateCarree()\n",
    "\n",
    "    # plot the RGB false color image\n",
    "    fig, ax = plt.subplots(figsize=(7, 7), subplot_kw={'projection': projection})\n",
    "    rgb.plot.imshow(ax=ax)\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([-3.5, 1.5, 49.5, 53.5], crs=projection)\n",
    "    \n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, alpha=0)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # add marker for Oxford\n",
    "    oxford_lon, oxford_lat = -1.2577, 51.7520\n",
    "    ax.plot(oxford_lon, oxford_lat, marker='x', color='white', markersize=6, label=\"Oxford\", transform=projection)\n",
    "    ax.text(oxford_lon-0.3, oxford_lat-0.3, 'Oxford', color='white', weight='bold', fontsize=10)\n",
    "    \n",
    "    # draw a rectangle around the area we are interested in\n",
    "    lons = [patch.x.min(), patch.x.max(), patch.x.max(), patch.x.min(), patch.x.min()]\n",
    "    lats = [patch.y.min(), patch.y.min(), patch.y.max(), patch.y.max(), patch.y.min()]\n",
    "    ax.plot(lons, lats, color='red', linewidth=1, transform=projection)\n",
    "    \n",
    "    ax.set_title(f\"MODIS RGB false color image (R: {rgb_bands[0]}, G: {rgb_bands[1]}, B: {rgb_bands[2]})\")\n",
    "\n",
    "plot_rgb_false_color(xr.load_dataset(modis_image_files[300]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Look at a few different MODIS images. Do you notice any aspects of the data that we need to take into account when developing our ML pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rgb_false_color(xr.load_dataset(modis_image_files[...]))\n",
    "plot_rgb_false_color(...)\n",
    "plot_rgb_false_color(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Baseline\n",
    "It's always a good idea to build a very simple model for the task we're trying to solve to get a performance baseline that we can compare more elaborate ML approaches to. For our baseline, we won't use MODIS images yet but explore how well a simple ML model - a Random Forest - can predict the amount of sun each afternoon (between 1 and 8:59pm) using the amount of sun each afternoon of the previous 3 days as input. This exercise enables us to think through a few crucial choices we need to make when developing our ML pipeline.\n",
    "\n",
    "#### 3.1. Training and Test Dataset\n",
    "First, we need to split our dataset into a training, validation and test set.\n",
    "\n",
    "**Question:** How should we split our inputs? One option would be to use January to October for training our model, and to set aside November and December for validation and testing, respectively. Another option would be to use every other month for training, and split the other months into validation and test months. Will our choice affect model performance? Why (not)? Could we just create our input (preceding 3 days of sun observation) and output (amount of sun between 3 and 4pm) matrices and randomly choose 80% of entries for training and 20% for testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_READY = DATA_PATH / 'ml-ready'\n",
    "\n",
    "if not ML_READY.exists():\n",
    "    with tempfile.NamedTemporaryFile() as tmp:\n",
    "        print(\"Downloading https://zenodo.org/records/14203536/files/ml-ready.zip\")\n",
    "        urllib.request.urlretrieve(\n",
    "            \"https://zenodo.org/records/14203536/files/ml-ready.zip\", tmp.name\n",
    "        )\n",
    "        print(\"Extracting ml-ready.zip\")\n",
    "        with zipfile.ZipFile(tmp, 'r') as zip_ref:\n",
    "            zip_ref.extractall(DATA_PATH)\n",
    "    \n",
    "    assert ML_READY.exists(), \"Download failed!\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATION_PATH = ML_READY / 'weatherstation'\n",
    "# read the dataframes\n",
    "X_train_df = pd.read_csv(f'{STATION_PATH}/train_df.csv')\n",
    "X_val_df = pd.read_csv(f'{STATION_PATH}/val_df.csv')\n",
    "X_test_df = pd.read_csv(f'{STATION_PATH}/test_df.csv')\n",
    "\n",
    "# read the target values\n",
    "y_train_df = pd.read_csv(f'{STATION_PATH}/y_train_df.csv')\n",
    "y_val_df = pd.read_csv(f'{STATION_PATH}/y_val_df.csv')\n",
    "y_test_df = pd.read_csv(f'{STATION_PATH}/y_test_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can see the variables that were included in the input features (`X_..._df`) and target values (`y_..._df`). Variables measured a day before the target date are denoted as `var_i-1`, two days before is `var_i-2` and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('columns in X_..._df:')\n",
    "print(X_train_df.keys().to_numpy())\n",
    "\n",
    "print('\\ncolumns in y_..._df:')\n",
    "print(y_train_df.keys().to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we only use the previous days of afternoon sun measurements as our input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the previous 3 days of afternoon sun measurements\n",
    "columns = [c for c in X_train_df.keys() if c.startswith('total_sun_1to8pm')]\n",
    "\n",
    "# convert the dataframes into numpy arrays for sklearn models\n",
    "X_train = X_train_df[columns].values\n",
    "X_val = X_val_df[columns].values\n",
    "X_test = X_test_df[columns].values\n",
    "\n",
    "y_train = y_train_df['total_sun_1to8pm'].values\n",
    "y_val = y_val_df['total_sun_1to8pm'].values\n",
    "y_test = y_test_df['total_sun_1to8pm'].values\n",
    "\n",
    "# create list of dates for plotting\n",
    "y_dates_train = [pd.to_datetime(date).date() for date in X_train_df['date'].values]\n",
    "y_dates_val = [pd.to_datetime(date).date() for date in X_val_df['date'].values]\n",
    "y_dates_test = [pd.to_datetime(date).date() for date in X_test_df['date'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Training our Random Forest\n",
    "Now, it's time to train our first model! We'll use the `scikit-learn` (abbreviated as `sklearn`) implementation of a `RandomForestRegressor`, and assess model performance using mean squared error (MSE):\n",
    "\n",
    "MSE $ = \\frac{1}{n} \\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^2$\n",
    "\n",
    "($n = $ number of data points; $Y_{i}\t=$ observed values; $\\hat{Y}_{i}=$ predicted value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# set the random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# create and train the model\n",
    "model = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the model using input features and targets\n",
    "model.fit(..., ...)\n",
    "\n",
    "# make predictions on training and validation inputs\n",
    "y_pred_train = model.predict(...)\n",
    "y_pred_val = model.predict(...)\n",
    "\n",
    "# calculate the mean squared error\n",
    "rmse_train = root_mean_squared_error(..., ...)\n",
    "rmse_val = root_mean_squared_error(..., ...)\n",
    "\n",
    "print(f'Training RMSE: {rmse_train:.4f}')\n",
    "print(f'Validation RMSE: {rmse_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to plot the time series predictions\n",
    "def plot_time_series_predictions(\n",
    "        y_true, \n",
    "        y_dates, \n",
    "        y_pred_train,\n",
    "        y_pred_val, \n",
    "        y_dates_train, \n",
    "        y_dates_val,\n",
    "        xlim=(pd.Timestamp('2021-01-01'), pd.Timestamp('2021-03-01'))\n",
    "    ):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(y_dates,\n",
    "            y_true,\n",
    "            '-x',\n",
    "            label='Measurements',\n",
    "            linewidth=1,\n",
    "            markersize=4,\n",
    "            markeredgewidth=1.5,)\n",
    "\n",
    "    plt.plot(y_dates_train, y_pred_train, '*', label='Predicted (train)')\n",
    "    plt.plot(y_dates_val, y_pred_val, '*', label='Predicted (val)')\n",
    "    plt.xlim(xlim)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "all_measurements = weather_station['total_sun_1to8pm'].to_numpy()\n",
    "all_measurements[(all_measurements > 8) | (all_measurements < 0)] = np.nan\n",
    "\n",
    "plot_time_series_predictions(\n",
    "    y_true=all_measurements[3:],\n",
    "    y_dates=weather_station['date'][3:],\n",
    "    y_pred_train=y_pred_train,\n",
    "    y_pred_val=y_pred_val,\n",
    "    y_dates_train=y_dates_train,\n",
    "    y_dates_val=y_dates_val,\n",
    "    xlim=(pd.Timestamp('2019-01-01'), pd.Timestamp('2020-12-31'))\n",
    ")\n",
    "\n",
    "plt.title('Sun predictions (2019-2020)')\n",
    "plt.show()\n",
    "\n",
    "plot_time_series_predictions(\n",
    "    y_true=all_measurements[3:],\n",
    "    y_dates=weather_station['date'][3:],\n",
    "    y_pred_train=y_pred_train,\n",
    "    y_pred_val=y_pred_val,\n",
    "    y_dates_train=y_dates_train,\n",
    "    y_dates_val=y_dates_val,\n",
    "    xlim=(pd.Timestamp('2020-03-01'), pd.Timestamp('2020-08-31'))\n",
    ")\n",
    "\n",
    "plt.title('Sun predictions (March to August 2020)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Metrics\n",
    "\n",
    "Our first model has an RMSE of 0.73 sun-hours on the training set, and 1.75 sun-hours on the validation set. Is this good? How much skill does the model need to have to achieve these scores? We can't answer this question using RMSE alone. To get further insights, we plot the actual vs. predicted values in a scatterplot, and compute the R^2 Score on the training and validation datasets.\n",
    "\n",
    "**Question:** How well do predictions follow the observed values? What do you notice about the predictions of the RandomForest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# calculate the R^2 score on the true and predicted targets\n",
    "r2_train = r2_score(..., ...)\n",
    "r2_val = r2_score(..., ...)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_train, y_pred_train, color='blue', label=rf'Training $R^2$: {r2_train:.4f}', alpha=0.7)\n",
    "plt.scatter(y_val, y_pred_val, color='orange', label=rf'Validation $R^2$: {r2_val:.4f}', alpha=0.7)\n",
    "\n",
    "# reference line (y = x)\n",
    "max_val = max(max(y_train), max(y_val), max(y_pred_train), max(y_pred_val))\n",
    "min_val = min(min(y_train), min(y_val), min(y_pred_train), min(y_pred_val))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='black', linestyle='--', label='Perfect Model')\n",
    "\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Overfitting\n",
    "**Question:** The Random Forest seems to be overfitting to the training dataset (how do we know this?). We don't expect great model performance, but this seems quite severe. Read the documentation of the [RandomForestRegressor](https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.RandomForestRegressor.html). Are there any parameters which could improve this issue? Choose 1 or 2 hyperparameters and test whether you can improve validation performance by changing its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters -- change the values of some of the model's hyperparameters\n",
    "hparams = {\n",
    "    'max_depth': ...,\n",
    "}\n",
    "\n",
    "# create and train the model\n",
    "model = RandomForestRegressor(**hparams, random_state=RANDOM_SEED)\n",
    "model.fit(..., ...)\n",
    "\n",
    "# make predictions\n",
    "y_pred_train = model.predict(...)\n",
    "y_pred_val = model.predict(...)\n",
    "\n",
    "# calculate the mean squared error\n",
    "rmse_train = root_mean_squared_error(..., ...)\n",
    "rmse_val = root_mean_squared_error(..., ...)\n",
    "\n",
    "print(f'Training RMSE: {rmse_train:.4f}')\n",
    "print(f'Validation RMSE: {rmse_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the R^2 score\n",
    "r2_train = r2_score(..., ...)\n",
    "r2_val = r2_score(..., ...)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_train, y_pred_train, color='blue', label=rf'Training $R^2$: {r2_train:.4f}', alpha=0.7)\n",
    "plt.scatter(y_val, y_pred_val, color='orange', label=rf'Validation $R^2$: {r2_val:.4f}', alpha=0.7)\n",
    "\n",
    "# Reference line (y = x)\n",
    "max_val = max(max(y_train), max(y_val), max(y_pred_train), max(y_pred_val))\n",
    "min_val = min(min(y_train), min(y_val), min(y_pred_train), min(y_pred_val))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='black', linestyle='--', label='Perfect Model')\n",
    "\n",
    "# Plot formatting\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our baseline still shows poor predictive skill on the validation set, and is far from being a perfect model. Let's try and improve predictions by exploiting our satellite dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Development\n",
    "Now that we've explored our data and trained a first baseline model, we will develop our `pytorch lightning` (https://lightning.ai/docs/pytorch/stable/) training pipeline that integrates MODIS observations. Our pipeline will consist of a dataloader, model, trainer, and evaluation metrics. As you will see, the pipeline is designed in a modular way. This enables flexible experimentation, as you can easily replace the model used as an example with a model of your choice, adapt the datasets to use other inputs, ...\n",
    "\n",
    "\n",
    "#### 4.1. Dataset and Dataloader\n",
    "Creating our own dataset and dataloader ensures that our data is correctly normalised, formatted, etc. so it can be passed to the lightning model. These custom components also enable efficient batching and shuffling, and optimize training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime\n",
    "\n",
    "# helper function to extract the date from a MODIS filename\n",
    "def get_date_from_modis_filename(filename: str) -> datetime:\n",
    "    return datetime.strptime(filename.split(\"/\")[-1][9:22], \"A%Y%j.%H%M\")\n",
    "\n",
    "class SunnyOxfordDataset(Dataset):   \n",
    "    # helper function to match a MODIS image with an AOPP observation\n",
    "    def _match_aopp_observation(self, modis_filename: str) -> dict:\n",
    "        modis_date = get_date_from_modis_filename(modis_filename)\n",
    "        aopp_row = self.aopp_dataframe[self.aopp_dataframe[\"date\"].dt.date == modis_date.date()]\n",
    "        if len(aopp_row) == 0:\n",
    "            print(f\"No AOPP observation found for {modis_date}\")\n",
    "            return None\n",
    "        else:\n",
    "            return aopp_row.to_dict(orient=\"records\")[0]\n",
    "        \n",
    "    def __init__(\n",
    "        self,\n",
    "        modis_filenames: list[str],\n",
    "        aopp_dataframe: pd.DataFrame,\n",
    "        station_inputs: list[str],\n",
    "        bands: list[str] = ['1'],\n",
    "        norm_params: pd.DataFrame | None = None,\n",
    "        target_minmax: tuple[float] = (0, 8) # sun1to8pm is between 0 and 8\n",
    "    ):\n",
    "        self.modis_filenames = modis_filenames\n",
    "        self.aopp_dataframe = aopp_dataframe\n",
    "        self.station_inputs = station_inputs\n",
    "        self.bands = bands\n",
    "        if norm_params is not None:\n",
    "            self.norm_params = norm_params\n",
    "\n",
    "        self.target_minmax = target_minmax\n",
    "\n",
    "\n",
    "    def __getitem__(self, ind) -> np.ndarray:\n",
    "        item = {}\n",
    "        ds = xr.load_dataset(self.modis_filenames[ind])\n",
    "\n",
    "        # reduce the resolution of the image by taking every second pixel and crop to 64x64 pixels\n",
    "        ds = ds.isel(x=slice(60,188,2), y=slice(60,188,2))\n",
    "\n",
    "\n",
    "        # select the bands to keep\n",
    "        x = np.array([ds[band].values for band in self.bands])\n",
    "\n",
    "        # normalise each band of the input image\n",
    "        if self.norm_params is not None:\n",
    "            for i, band in enumerate(self.bands):\n",
    "                band_mean = self.norm_params[self.norm_params['band'] == band]['mean'].values[0]\n",
    "                band_std = self.norm_params[self.norm_params['band'] == band]['std'].values[0]\n",
    "                x[i, :, :] = (x[i, :, :] - band_mean) / band_std\n",
    "\n",
    "        # fill NaN values in each band with the mean of the non-NaN values of that band\n",
    "        for i in range(x.shape[0]):\n",
    "            if np.isnan(np.nanmean(x[i, :, :])):\n",
    "                print(f'all nan for file {self.modis_filenames[ind]}')\n",
    "            x[i, :, :] = np.nan_to_num(x[i, :, :], nan=np.nanmean(x[i, :, :]))\n",
    "\n",
    "        # convert to tensor\n",
    "        x = torch.as_tensor(x, dtype=torch.float32)\n",
    "\n",
    "        item[\"modis_image\"] = x\n",
    "        \n",
    "        for key, value in self._match_aopp_observation(self.modis_filenames[ind]).items():\n",
    "            if key in self.station_inputs:\n",
    "                value = np.array(value)\n",
    "                value_scaled = (value - self.target_minmax[0]) / (self.target_minmax[1] - self.target_minmax[0])\n",
    "                item[key] = torch.as_tensor(value_scaled, dtype=torch.float32)\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.modis_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SunnyOxfordDatamodule(LightningDataModule):\n",
    "    def _split_modis_files(self, modis_filenames: list[str], years: list[int]) -> list[str]:\n",
    "        return [f for f in modis_filenames if get_date_from_modis_filename(f).year in years]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        modis_filenames: list[str],\n",
    "        split_years: dict,\n",
    "        station_df: pd.DataFrame,\n",
    "        bands: list[str] = ['1'],\n",
    "        station_inputs: list[str] = ['total_sun_1to8pm'],\n",
    "        batch_size: int = 4,\n",
    "        normalisation_file: str = None,\n",
    "        num_workers: int = 8\n",
    "    \n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.data_dir = data_dir\n",
    "        self.modis_filenames = modis_filenames\n",
    "        self.split_years = split_years\n",
    "        self.station_df = station_df\n",
    "        self.bands = bands\n",
    "        self.station_inputs = station_inputs\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # load normalisation parameters\n",
    "        self.norm_df = pd.read_csv(normalisation_file)\n",
    "        self.norm_df['band'] = self.norm_df['band'].astype(str) # for matching with band names\n",
    "\n",
    "        # split filenames based on train/test/val criteria\n",
    "        train_modis_files = self._split_modis_files(self.modis_filenames, split_years['train'])\n",
    "        val_modis_files = self._split_modis_files(self.modis_filenames, split_years['validation'])\n",
    "        test_modis_files = self._split_modis_files(self.modis_filenames, split_years['test'])\n",
    "        \n",
    "\n",
    "        self.train_dataset = SunnyOxfordDataset(\n",
    "            modis_filenames=train_modis_files,\n",
    "            aopp_dataframe=self.station_df,\n",
    "            bands=self.bands,\n",
    "            norm_params=self.norm_df,\n",
    "            station_inputs=self.station_inputs\n",
    "        )\n",
    "\n",
    "        self.val_dataset = SunnyOxfordDataset(\n",
    "            modis_filenames=val_modis_files,\n",
    "            aopp_dataframe=self.station_df,\n",
    "            bands=self.bands,\n",
    "            norm_params=self.norm_df,\n",
    "            station_inputs=self.station_inputs\n",
    "        )\n",
    "\n",
    "        self.test_dataset = SunnyOxfordDataset(\n",
    "            modis_filenames=test_modis_files,\n",
    "            aopp_dataframe=self.station_df,\n",
    "            bands=self.bands,\n",
    "            norm_params=self.norm_df,\n",
    "            station_inputs=self.station_inputs\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Model Architecture\n",
    "Next, we define our model architecture. For now, we'll use a simple convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lightning import LightningModule\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(LightningModule):\n",
    "    def __init__(self, lr=1e-3):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.lr = lr\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)  # Flattened size after pooling\n",
    "        self.fc2 = nn.Linear(256, 1)  # Single output for regression\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x, return_embeddings=False):\n",
    "        # Forward pass\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if return_embeddings:\n",
    "            return x\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Training step\n",
    "        images = batch['modis_image']\n",
    "        targets = batch['total_sun_1to8pm'].unsqueeze(1) # inserting a dimension for the 1D output to match the model output\n",
    "        predictions = self(images)\n",
    "        loss = F.mse_loss(predictions, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Validation step\n",
    "        images = batch['modis_image']\n",
    "        targets = batch['total_sun_1to8pm'].unsqueeze(1) # inserting a dimension for the 1D output to match the model output\n",
    "        predictions = self(images)\n",
    "        loss = F.mse_loss(predictions, targets)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Training\n",
    "It's time to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "seed_everything(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "split_years = {\n",
    "    'train': [2016, 2017, 2018, 2019],\n",
    "    'validation' : [2020],\n",
    "    'test' : [2021]\n",
    "}\n",
    "\n",
    "STATION_PATH = os.path.join(DATA_PATH, 'ml-ready', 'weatherstation')\n",
    "# read the datasets\n",
    "X_train_df = pd.read_csv(f'{STATION_PATH}/train_df.csv')\n",
    "X_val_df = pd.read_csv(f'{STATION_PATH}/val_df.csv')\n",
    "X_test_df = pd.read_csv(f'{STATION_PATH}/test_df.csv')\n",
    "\n",
    "# read target values\n",
    "y_train_df = pd.read_csv(f'{STATION_PATH}/y_train_df.csv')\n",
    "y_val_df = pd.read_csv(f'{STATION_PATH}/y_val_df.csv')\n",
    "y_test_df = pd.read_csv(f'{STATION_PATH}/y_test_df.csv')\n",
    "\n",
    "# make date column datetime in y_..._dfs\n",
    "y_train_df['date'] = pd.to_datetime(y_train_df['date'])\n",
    "y_val_df['date'] = pd.to_datetime(y_val_df['date'])\n",
    "y_test_df['date'] = pd.to_datetime(y_test_df['date'])\n",
    "\n",
    "# concatenate the weather station \n",
    "station_df = pd.concat([y_train_df, y_val_df, y_test_df], ignore_index=True)\n",
    "\n",
    "modis_filenames = pd.read_csv(DATA_PATH/'ml-ready'/'modis'/'valid_files_with_obs.csv')['0'].to_list()\n",
    "\n",
    "modis_filenames = [str(DATA_PATH/\"modis\"/file.split(\"/\")[-1]) for file in modis_filenames]\n",
    "\n",
    "datamodule = SunnyOxfordDatamodule(\n",
    "    modis_filenames=modis_filenames,\n",
    "    split_years=split_years,\n",
    "    station_df=station_df,\n",
    "    bands=[...], # for now, choose one of the available bands\n",
    "    station_inputs=['total_sun_1to8pm'],\n",
    "    batch_size=8,\n",
    "    normalisation_file=os.path.join(DATA_PATH, 'ml-ready', 'modis', 'normalisation_params_train.csv'), \n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(\"logs\", name=\"sunny-oxford\")\n",
    "\n",
    "num_epochs = ...\n",
    "\n",
    "# initialize the trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=10)],\n",
    "    logger=logger,\n",
    "    devices=1,\n",
    "    accelerator='auto',\n",
    ")\n",
    "\n",
    "# initialize model and train\n",
    "model = SimpleCNN(lr=...)\n",
    "trainer.fit(model, datamodule.train_dataloader(), datamodule.val_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute validation metrics on the best model\n",
    "trainer.validate(model, datamodule.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model in eval mode to assemble validation predictions\n",
    "model.eval()\n",
    "\n",
    "# Store true values and predictions\n",
    "all_true_values = []\n",
    "all_predictions = []\n",
    "\n",
    "# Iterate through the validation DataLoader\n",
    "with torch.no_grad():  # Disable gradient calculations\n",
    "    for batch in datamodule.val_dataloader():\n",
    "        images = batch['modis_image']\n",
    "        targets = batch['total_sun_1to8pm'].cpu().numpy()\n",
    "        \n",
    "        # Forward pass: Get model predictions\n",
    "        predictions = model(images).squeeze().cpu().numpy()\n",
    "\n",
    "        # un-normalise the predictions and targets\n",
    "        predictions = predictions * 8\n",
    "        targets = targets * 8\n",
    "        \n",
    "        # Store the true values and predictions\n",
    "        all_true_values.append(targets)  # Convert to numpy array to store\n",
    "        all_predictions.append(predictions)  # Convert to numpy array to store\n",
    "\n",
    "# Convert lists to 1D numpy arrays\n",
    "all_true_values = np.concatenate(all_true_values, axis=0)\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# calculate the R^2 score\n",
    "r2_val = r2_score(all_true_values, all_predictions)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# validation scatter\n",
    "plt.scatter(all_true_values, all_predictions, color='orange', label=rf'Validation $R^2$: {r2_val:.4f}', alpha=0.7)\n",
    "# reference line (y = x)\n",
    "plt.plot([min(all_true_values), max(all_true_values)], [min(all_true_values), max(all_true_values)], '--', color='black', lw=2, label='Perfect Model')\n",
    "\n",
    "# plot formatting\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** The model outperforms our simple baseline - but is this as good as it gets? The rest of this notebook contain a few suggestions for further experiments. What's the best model that you can build for this task? There seems to be some useful information contained in the simple timeseries of weather station measurements, as well as in the MODIS images. Can you think of a way to combine the two?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a. The (Feature) Importance of Environmental Inputs\n",
    "In this part of the lab, you can explore whether the model benefits from receiving additional weather station measurements as input.\n",
    "Can you gain some insight into how important the different inputs are for predicting sunnyness? One suggestion is to use `SHAP` (SHapley Additive exPlanations) values. SHAP values quantify the contribution of each feature to a model's prediction by distributing the prediction difference (between the actual and baseline) among the features, based on cooperative game theory. They provide an interpretable way to study feature importance.\n",
    "\n",
    "Hints:\n",
    "- A simple starting point would be to use the `RandomForestRegressor` from our baseline, but use some of the other columns available in the ML-ready station observations (i.e. in `X_train_df = pd.read_csv(f'{STATION_PATH}/train_df.csv`). Which columns have high feature importances? Is this as you would expect it to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b. Predictability\n",
    "We have trained a model that shows promising skill in predicting sunnyness a few hours ahead. But how does model performance change when we try to predict sunnyness a day, two days, a week ahead? What would you expect, generally, and based on the autocorrelation plots from the start of the lab? If we had a perfect machine learning model, and perfect observations of all environmental variables that will affect how sunny it is -- would we be able to predict whether it will be sunny, infinitely far in the future? Why (not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.c. Improving predictions\n",
    "The two simple models, one trained on past weather station observations, one trained on MODIS satellite images, show some predictive skill - but are far from being perfect. Can you think of other ML approaches that could yield more skillful predictors, for example, by combining the different data sources that we have access to?\n",
    "\n",
    "- The `forward` method of the `SimpleCNN` that we've trained above has a `return_embeddings` option. You could use the embeddings of the trained model, in combination with some station measurements as input to a model of your choice (could be a Random Forest, but doesn't have to be!). Does this combination of satellite image and station observations enable the model to make better predictions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iecdt-earth-observation]",
   "language": "python",
   "name": "conda-env-iecdt-earth-observation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
